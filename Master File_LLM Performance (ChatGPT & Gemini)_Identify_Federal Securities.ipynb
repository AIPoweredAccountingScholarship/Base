{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab43e133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code adapted for OpenAI GPT API\n",
    "#Note: the code will run best when executing each section separately\n",
    "\n",
    "# 1. GPT identify federal securities laws\n",
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "import re\n",
    "from typing import List, Dict\n",
    "\n",
    "def get_securities_laws(conversation_history=None):\n",
    "    # Initialize the OpenAI client\n",
    "    client = openai.OpenAI(\n",
    "        api_key=\"enter API here\"\n",
    "    )\n",
    "    \n",
    "    # Initial prompt \n",
    "    initial_content = \"\"\"Your task is to identify and compile a comprehensive database of at least 100 federal securities \n",
    "    laws. Securities regulation is the field of U.S. law that covers transactions and other dealings with securities. \n",
    "    Securities laws aim at ensuring that investors receive accurate and necessary information regarding the type and value\n",
    "    of the interest under consideration for purchase.\n",
    "\n",
    "IMPORTANT: Only identify new securities regulations. Exclude amendments, updates, or revisions to existing rules. \n",
    "Focus on major new laws only.\n",
    "\n",
    "IMPORTANT: Do not include laws with titles containing the following words: \"Amendment\", \"Update\", or \"Revision\"\n",
    "\n",
    "The goal is to create a dataset that captures the following key details for each law. \n",
    "\n",
    "Please follow these guidelines:\n",
    "\n",
    "Data Fields to Collect:\n",
    "• Date: The announcement or implementation date of the law (use YYYY-MM-DD format).\n",
    "• Regulation Title or Name: The official name or designation of the regulatory change.\n",
    "• Regulatory Body/Authority: The government entity responsible for the law.\n",
    "• Description: A brief overview of the law, including key provisions and the rationale behind it.\n",
    "• Impact: The potential or observed effects on industries, markets, or stakeholders.\n",
    "•Litigation Risk: Is this law related to the risk of litigation against managers? By risk of litigation we mean the probability that a manager will be sued or face legal action because of this law. Answer this question with Yes or No. If yes, label the entry \"Litigation Risk\".\n",
    "•Corporate Governance: Is this law related to corporate governance of firms? Corporate governance refers to the internal monitoring system charged with overseeing managers and commonly focuses on matters such as board independence or insider trading policy. Answer this question with Yes or No.If yes, label the entry \"Corporate Governance\".\n",
    "•Proprietary Costs: Is this law related to proprietary costs of firms? By proprietary costs, we mean costs that result from the disclosure of information to competitors which could harm a firm's competitive position. Answer this question with Yes or No.If yes, label the entry \"Proprietary Costs\".\n",
    "•Information Asymmetry: Is this law related to information asymmetry between owners and managers? By information asymmetry we mean that one party has more or better information than the other party. Answer this question with Yes or No. If yes, label the entry \"Information Asymmetry\".\n",
    "•Unsophisticated Investors: Is the law related to protecting unsophisticated investors? By unsophisticated investors, we mean investors that are either new to investing or are not well informed. Answer this question with Yes or No. If yes, label the entry \"Unsophisticated Investors\".\n",
    "•Equity Issuance in Public vs. Private Markets: Is this law related to the costs and benefits of issuing equity in public versus private markets? Answer this question with Yes or No. If yes, label the entry \"Equity Issuance in Public vs. Private Markets\".\n",
    "•Reputation Risk: Is this law related to the reputation of firm managers? By of firm manager, we mean the career prospects and prestige of an individual manager. Answer this question with Yes or No. If yes, label the entry \"Reputation Risk\".\n",
    "\n",
    "• References: Links to official documents or credible news sources.\n",
    "\n",
    "Requirements:\n",
    "• Scope: Cover as many laws as possible that were announced or implemented in the last 25 years.\n",
    "• Consistency: Ensure uniform formatting for all entries in the dataset.\n",
    "• Dates must be in YYYY-MM-DD format (e.g., 2002-07-30).\n",
    "\n",
    "Output:\n",
    "Provide data in a tabular format with rows for each law and columns for the data fields listed above. \n",
    "Use credible, authoritative sources such as government websites, legal databases, academic journals, or credible news sources.\n",
    "Do not include duplicate laws.\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        if conversation_history:\n",
    "            messages = conversation_history\n",
    "        else:\n",
    "            messages = [{\n",
    "                \"role\": \"user\",\n",
    "                \"content\": initial_content\n",
    "            }]\n",
    "\n",
    "        print(\"Making API call to GPT-4.1...\")\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4.1\",  \n",
    "            messages=messages,\n",
    "            max_tokens=8000,  # GPT-4.1 uses max_tokens, not max_completion_tokens\n",
    "            temperature=0.5 \n",
    "        )\n",
    "        \n",
    "        print(f\"Raw response object: {response}\")\n",
    "        print(f\"Response choices: {response.choices}\")\n",
    "        print(f\"First choice: {response.choices[0] if response.choices else 'No choices'}\")\n",
    "        \n",
    "        response_content = response.choices[0].message.content\n",
    "        print(f\"Response content type: {type(response_content)}\")\n",
    "        print(f\"Response content: {repr(response_content)}\")\n",
    "        print(f\"API call successful! Response length: {len(response_content) if response_content else 0} characters\")\n",
    "        \n",
    "        return response_content, messages + [\n",
    "            {\"role\": \"assistant\", \"content\": response_content}\n",
    "        ]\n",
    "    except Exception as e:\n",
    "        print(f\"Error making API call: {e}\")\n",
    "        return None, messages if conversation_history else []\n",
    "\n",
    "\n",
    "def add_follow_up_prompt(conversation_history, follow_up_prompt):\n",
    "    \"\"\"Add a follow-up prompt to the conversation history\"\"\"\n",
    "    return conversation_history + [{\"role\": \"user\", \"content\": follow_up_prompt}]\n",
    "\n",
    "def standardize_date(date_str):\n",
    "    \"\"\"Attempt to standardize date format to YYYY-MM-DD\"\"\"\n",
    "    try:\n",
    "        # Convert to datetime and then back to string in desired format\n",
    "        return pd.to_datetime(date_str).strftime('%Y-%m-%d')\n",
    "    except:\n",
    "        # If conversion fails, return original string\n",
    "        return date_str\n",
    "\n",
    "def parse_table_fallback(response_text: str) -> pd.DataFrame:\n",
    "    \"\"\"Fallback parser for when Claude returns table format instead of numbered format.\"\"\"\n",
    "    print(\"Debugging table parsing...\")\n",
    "    \n",
    "    lines = response_text.split('\\n')\n",
    "    table_lines = [line.strip() for line in lines if line.strip().startswith('|') and len(line.strip()) > 5]\n",
    "    \n",
    "    print(f\"Found {len(table_lines)} table lines\")\n",
    "    \n",
    "    if len(table_lines) < 2:\n",
    "        print(\"Not enough table lines found\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Remove separator lines (containing ---)\n",
    "    data_lines = [line for line in table_lines if '---' not in line]\n",
    "    print(f\"Found {len(data_lines)} data lines (after removing separators)\")\n",
    "    \n",
    "    if len(data_lines) < 2:\n",
    "        print(\"Not enough data lines after removing separators\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Parse header line\n",
    "    header_line = data_lines[0]\n",
    "    raw_headers = header_line.split('|')\n",
    "    headers = [col.strip() for col in raw_headers if col.strip()]\n",
    "    \n",
    "    print(f\"Original headers ({len(headers)}): {headers}\")\n",
    "    \n",
    "    # Parse data rows\n",
    "    data_rows = []\n",
    "    for i, line in enumerate(data_lines[1:], 1):\n",
    "        raw_columns = line.split('|')\n",
    "        columns = [col.strip() for col in raw_columns if col.strip()]\n",
    "        \n",
    "        if len(columns) == len(headers):\n",
    "            data_rows.append(columns)\n",
    "            print(f\"Row {i}: ✓ Added ({len(columns)} columns)\")\n",
    "        else:\n",
    "            print(f\"Row {i}: ✗ Skipped - {len(columns)} columns vs {len(headers)} headers\")\n",
    "    \n",
    "    print(f\"Successfully parsed {len(data_rows)} data rows\")\n",
    "    \n",
    "    if not data_rows:\n",
    "        print(\"No valid data rows found\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Create DataFrame with original headers first\n",
    "    df = pd.DataFrame(data_rows, columns=headers)\n",
    "    print(f\"Created DataFrame with columns: {list(df.columns)}\")\n",
    "\n",
    "    # Make the mapping more robust for title column\n",
    "    for col in df.columns:\n",
    "        if 'title' in col.lower() or 'name' in col.lower():\n",
    "            df = df.rename(columns={col: 'Regulation Title'})\n",
    "            print(f\"Mapped column '{col}' to 'Regulation Title'\")\n",
    "            break\n",
    "            \n",
    "    # Now standardize the column names to match expected format\n",
    "    # Create a mapping from the table headers to standard column names\n",
    "    standard_columns = {\n",
    "        'Date': 'Date',\n",
    "        'Regulation Title/Name': 'Regulation Title', \n",
    "        'Regulatory Body': 'Regulatory Body',\n",
    "        'Regulatory Body/Authority': 'Regulatory Body',  # Handle variation\n",
    "        'Description': 'Description',\n",
    "        'Impact': 'Impact',\n",
    "        'Litigation Risk': 'Litigation Risk',\n",
    "        'Corporate Governance': 'Corporate Governance', \n",
    "        'Proprietary Costs': 'Proprietary Costs',\n",
    "        'Information Asymmetry': 'Information Asymmetry',\n",
    "        'Unsophisticated Investors': 'Unsophisticated Investors',\n",
    "        'Equity Issuance Public vs Private': 'Equity Issuance',\n",
    "        'Equity Issuance in Public vs. Private Markets': 'Equity Issuance',  # Handle variation\n",
    "        'Reputation Risk': 'Reputation Risk',\n",
    "        'References': 'References'\n",
    "    }\n",
    "    \n",
    "    # Rename columns using the mapping\n",
    "    df_renamed = df.rename(columns=standard_columns)\n",
    "    \n",
    "    # Ensure all required columns exist\n",
    "    required_columns = [\n",
    "        'Date', 'Regulation Title', 'Regulatory Body', 'Description', 'Impact',\n",
    "        'Litigation Risk', 'Corporate Governance', 'Proprietary Costs', \n",
    "        'Information Asymmetry', 'Unsophisticated Investors', 'Equity Issuance',\n",
    "        'Reputation Risk', 'References'\n",
    "    ]\n",
    "    \n",
    "    # Add missing columns with None values\n",
    "    for col in required_columns:\n",
    "        if col not in df_renamed.columns:\n",
    "            print(f\"Adding missing column: {col}\")\n",
    "            df_renamed[col] = None\n",
    "    \n",
    "    # Select only the required columns in the correct order\n",
    "    final_df = df_renamed[required_columns].copy()\n",
    "    \n",
    "    # Standardize date format\n",
    "    if 'Date' in final_df.columns:\n",
    "        print(\"Standardizing dates...\")\n",
    "        final_df['Date'] = final_df['Date'].apply(lambda x: standardize_date(x) if pd.notna(x) and str(x).strip() else x)\n",
    "    \n",
    "    # Clean up any completely empty rows\n",
    "    final_df = final_df.dropna(how='all')\n",
    "    \n",
    "    print(f\"Final DataFrame: {len(final_df)} rows x {len(final_df.columns)} columns\")\n",
    "    print(f\"Final columns: {list(final_df.columns)}\")\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "def parse_bullet_format(response_text: str) -> pd.DataFrame:\n",
    "    \"\"\"Parse GPT response in numbered + markdown bullet format.\"\"\"\n",
    "    import re\n",
    "    entries = []\n",
    "    current_entry = {}\n",
    "    entry_number = None\n",
    "\n",
    "    lines = [line.strip() for line in response_text.split(\"\\n\") if line.strip()]\n",
    "\n",
    "    for line in lines:\n",
    "        # Detect new numbered law like \"4.\" or \"12.\"\n",
    "        number_match = re.match(r'^(\\d+)\\.', line)\n",
    "        if number_match:\n",
    "            if current_entry:\n",
    "                entries.append(current_entry)\n",
    "            current_entry = {}\n",
    "            entry_number = number_match.group(1)\n",
    "            continue\n",
    "\n",
    "        # Detect bullet fields like \"- **Date**: 1996-10-11\"\n",
    "        bullet_match = re.match(r'^-\\s*\\*\\*(.+?)\\*\\*:\\s*(.+)', line)\n",
    "        if bullet_match and current_entry is not None:\n",
    "            key, value = bullet_match.groups()\n",
    "            key = key.strip()\n",
    "            value = value.strip()\n",
    "\n",
    "            key_mapping = {\n",
    "                \"Date\": \"Date\",\n",
    "                \"Title\": \"Regulation Title\",\n",
    "                \"Authority\": \"Regulatory Body\",\n",
    "                \"Description\": \"Description\",\n",
    "                \"Impact\": \"Impact\",\n",
    "                \"Litigation Risk\": \"Litigation Risk\",\n",
    "                \"Corporate Governance\": \"Corporate Governance\",\n",
    "                \"Proprietary Costs\": \"Proprietary Costs\",\n",
    "                \"Information Asymmetry\": \"Information Asymmetry\",\n",
    "                \"Unsophisticated Investors\": \"Unsophisticated Investors\",\n",
    "                \"Equity Issuance\": \"Equity Issuance\",\n",
    "                \"Reputation Risk\": \"Reputation Risk\",\n",
    "                \"References\": \"References\"\n",
    "            }\n",
    "\n",
    "            if key in key_mapping:\n",
    "                current_entry[key_mapping[key]] = value\n",
    "\n",
    "    # Append last entry\n",
    "    if current_entry:\n",
    "        entries.append(current_entry)\n",
    "\n",
    "    if not entries:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df = pd.DataFrame(entries)\n",
    "\n",
    "    # Ensure all required columns\n",
    "    required_columns = [\n",
    "        'Date', 'Regulation Title', 'Regulatory Body', 'Description', 'Impact',\n",
    "        'Litigation Risk', 'Corporate Governance', 'Proprietary Costs',\n",
    "        'Information Asymmetry', 'Unsophisticated Investors', 'Equity Issuance',\n",
    "        'Reputation Risk', 'References'\n",
    "    ]\n",
    "    for col in required_columns:\n",
    "        if col not in df.columns:\n",
    "            df[col] = None\n",
    "\n",
    "    return df[required_columns]\n",
    "    \n",
    "def parse_response_to_dataframe(response_text: str) -> pd.DataFrame:\n",
    "    \"\"\"Parse the response text into a pandas DataFrame.\"\"\"\n",
    "    print(\"\\nParsing response...\")\n",
    "    \n",
    "    # First try the original numbered format parsing\n",
    "    data = []\n",
    "    current_entry = None\n",
    "    entry_number = None\n",
    "    \n",
    "    lines = [line.strip() for line in response_text.split('\\n') if line.strip()]\n",
    "    \n",
    "    for line in lines:\n",
    "        number_match = re.match(r'^\\*?\\*?(\\d+)\\.\\*?\\*?', line)\n",
    "        if number_match:\n",
    "            if current_entry and len(current_entry) > 0:\n",
    "                if 'Regulation Title' not in current_entry and entry_number:\n",
    "                    current_entry['Regulation Title'] = f\"Law {entry_number}\"\n",
    "                data.append(current_entry)\n",
    "            current_entry = {}\n",
    "            entry_number = number_match.group(1)\n",
    "            continue\n",
    "            \n",
    "        if ':' in line and current_entry is not None:\n",
    "            key, value = [x.strip() for x in line.split(':', 1)]\n",
    "            \n",
    "            key_mapping = {\n",
    "                'Date': 'Date',\n",
    "                'Title': 'Regulation Title',\n",
    "                'Authority': 'Regulatory Body',\n",
    "                'Description': 'Description',\n",
    "                'Impact': 'Impact',\n",
    "                'Litigation Risk': 'Litigation Risk',\n",
    "                'Corporate Governance': 'Corporate Governance',\n",
    "                'Proprietary Costs': 'Proprietary Costs',\n",
    "                'Information Asymmetry': 'Information Asymmetry',\n",
    "                'Unsophisticated Investors': 'Unsophisticated Investors',\n",
    "                'Equity Issuance': 'Equity Issuance',\n",
    "                'Reputation Risk': 'Reputation Risk',\n",
    "                'References': 'References'\n",
    "            }\n",
    "            \n",
    "            if key in key_mapping:\n",
    "                column_name = key_mapping[key]\n",
    "                if column_name == 'Date':\n",
    "                    current_entry[column_name] = standardize_date(value)\n",
    "                else:\n",
    "                    current_entry[column_name] = value.strip()\n",
    "\n",
    "    if current_entry and len(current_entry) > 0:\n",
    "        if 'Regulation Title' not in current_entry and entry_number:\n",
    "            current_entry['Regulation Title'] = f\"Law {entry_number}\"\n",
    "        data.append(current_entry)\n",
    "\n",
    "    print(f\"\\nFound {len(data)} entries in numbered format\")\n",
    "\n",
    "    if data:\n",
    "        df = pd.DataFrame(data)\n",
    "        required_columns = [\n",
    "            'Date', 'Regulation Title', 'Regulatory Body', 'Description', 'Impact',\n",
    "            'Litigation Risk', 'Corporate Governance', 'Proprietary Costs',\n",
    "            'Information Asymmetry', 'Unsophisticated Investors', 'Equity Issuance',\n",
    "            'Reputation Risk', 'References'\n",
    "        ]\n",
    "        for col in required_columns:\n",
    "            if col not in df.columns:\n",
    "                print(f\"Adding missing column: {col}\")\n",
    "                df[col] = None\n",
    "        df['Regulation Title'] = df['Regulation Title'].fillna('Unknown')\n",
    "        df['Regulation Title'] = df['Regulation Title'].apply(lambda x: re.sub(r'\\s+', ' ', x).strip())\n",
    "        df['dedup_key'] = df.apply(lambda row: f\"{row['Date']}_{row['Regulation Title']}\", axis=1)\n",
    "        df = df.drop_duplicates(subset=['dedup_key'], keep='first')\n",
    "        df = df.drop('dedup_key', axis=1)\n",
    "        df = df[required_columns]\n",
    "        print(f\"Created DataFrame with {len(df)} rows\")\n",
    "        return df.copy()\n",
    "\n",
    "    # If numbered format failed, try table format\n",
    "    print(\"Numbered format parsing failed, trying table format...\")\n",
    "    df = parse_table_fallback(response_text)\n",
    "    if not df.empty:\n",
    "        print(f\"Table format parsing succeeded with {len(df)} rows\")\n",
    "        return df\n",
    "\n",
    "    # If table format failed, try bullet format\n",
    "    print(\"Table format parsing failed, trying bullet format...\")\n",
    "    df = parse_bullet_format(response_text)\n",
    "    if not df.empty:\n",
    "        print(f\"Bullet format parsing succeeded with {len(df)} rows\")\n",
    "        return df\n",
    "\n",
    "    # All methods failed\n",
    "    print(\"All parsing methods failed - no valid data to create DataFrame\")\n",
    "    return pd.DataFrame()\n",
    "                \n",
    "def compile_all_responses() -> pd.DataFrame:\n",
    "    \"\"\"Compile multiple API responses into a single DataFrame.\"\"\"\n",
    "    all_responses = []\n",
    "    conversation_history = None\n",
    "\n",
    "    # Get initial response\n",
    "    initial_response, conversation_history = get_securities_laws()\n",
    "    if initial_response:\n",
    "        print(\"\\nInitial response:\")\n",
    "        print(\"=\"*50)\n",
    "        print(initial_response)\n",
    "        print(\"=\"*50)\n",
    "        print(f\"Response length: {len(initial_response)} characters\")\n",
    "        all_responses.append(initial_response)\n",
    "    else:\n",
    "        print(\"ERROR: No initial response received from API!\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Follow-up prompts for additional laws\n",
    "    follow_up_prompts = [\n",
    "        \"\"\"Starting with number {last_num}, list 20 more federal securities laws using this exact format for each:\n",
    "Date: YYYY-MM-DD\n",
    "Title: [title]\n",
    "Authority: [body]\n",
    "Description: [brief]\n",
    "Impact: [impact]\n",
    "Litigation Risk: Yes/No\n",
    "Corporate Governance: Yes/No\n",
    "Proprietary Costs: Yes/No\n",
    "Information Asymmetry: Yes/No\n",
    "Unsophisticated Investors: Yes/No\n",
    "Equity Issuance: Yes/No\n",
    "Reputation Risk: Yes/No\n",
    "References: [link]\"\"\",\n",
    "\n",
    "        \"Continue from number {last_num}. Provide 20 more laws using the exact same format.\",\n",
    "        \n",
    "        \"List 20 more laws starting at number {last_num}. Use the same format.\",\n",
    "        \n",
    "        \"Add 20 more laws beginning with number {last_num}. Keep the same format.\",\n",
    "        \n",
    "        \"Provide 20 more laws from number {last_num}. Same format.\",\n",
    "        \n",
    "        \"Recall that you have to identify at least 100 federal securities laws. Recall securities regulation is the field of U.S. law that covers transactions and other dealings with securities. Securities laws aim at ensuring that investors receive accurate and necessary information regarding the type and value of the interest under consideration for purchase.\"\n",
    "    ]\n",
    "    last_num = len(parse_response_to_dataframe(initial_response)) + 1\n",
    "    \n",
    "    for i, prompt_template in enumerate(follow_up_prompts, 1):\n",
    "        prompt = prompt_template.format(last_num=last_num)\n",
    "        conversation_history = add_follow_up_prompt(conversation_history, prompt)\n",
    "        response, conversation_history = get_securities_laws(conversation_history)\n",
    "        \n",
    "        if response:\n",
    "            print(f\"\\nFollow-up response {i}:\")\n",
    "            print(response)\n",
    "            all_responses.append(response)\n",
    "            df = parse_response_to_dataframe(response)\n",
    "            last_num += len(df)\n",
    "            \n",
    "    # Parse all responses into DataFrames and concatenate\n",
    "    dfs = []\n",
    "    for response in all_responses:\n",
    "        df = parse_response_to_dataframe(response)\n",
    "        if not df.empty:\n",
    "            dfs.append(df)\n",
    "\n",
    "    if not dfs:\n",
    "        print(\"No valid data frames were created!\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Concatenate all DataFrames\n",
    "    final_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    # Remove duplicates using multiple fields to better identify unique laws\n",
    "    final_df['Title_clean'] = final_df['Regulation Title'].fillna('').str.lower().str.strip()\n",
    "    final_df['Description_clean'] = final_df['Description'].fillna('').str.lower().str.strip()\n",
    "    \n",
    "    # Create composite key for deduplication\n",
    "    final_df['dedup_key'] = final_df.apply(\n",
    "        lambda row: f\"{row['Date']}_{row['Title_clean']}_{row['Description_clean'][:50]}\", \n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # Remove duplicates and cleanup\n",
    "    final_df = final_df.drop_duplicates(subset=['dedup_key'], keep='first')\n",
    "    final_df = final_df.drop(['Title_clean', 'Description_clean', 'dedup_key'], axis=1)\n",
    "\n",
    "    # Sort by date\n",
    "    try:\n",
    "        final_df['DateSort'] = pd.to_datetime(final_df['Date'], errors='coerce')\n",
    "        final_df = final_df.dropna(subset=['DateSort'])\n",
    "        final_df = final_df.sort_values('DateSort', ascending=False)\n",
    "        final_df = final_df.drop('DateSort', axis=1)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not sort by date due to: {e}\")\n",
    "        print(\"Problematic dates:\")\n",
    "        print(final_df['Date'].value_counts())\n",
    "\n",
    "    # Return the final DataFrame\n",
    "    return final_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Compile all responses into a DataFrame\n",
    "    df = compile_all_responses()\n",
    "    \n",
    "    if df.empty:\n",
    "        print(\"\\nError: No data was collected!\")\n",
    "    else:\n",
    "        # Display basic statistics\n",
    "        print(f\"\\nTotal number of unique laws: {len(df)}\")\n",
    "        print(\"\\nMost recent laws:\")\n",
    "        print(df.head().to_string())\n",
    "        \n",
    "        # Save to CSV\n",
    "        output_path = 'enter file path here'\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"\\nDatabase saved to: {output_path}\")\n",
    "        \n",
    "# 2. Add column for Year \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv('enter file path here')\n",
    "\n",
    "# Clean parentheses and dashes from text columns\n",
    "for column in df.select_dtypes(include=['object']).columns:\n",
    "    df[column] = df[column].str.replace('(', '').str.replace(')', '').str.replace('-', '')\n",
    "    \n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['Year'] = df['Date'].dt.year\n",
    "df\n",
    "\n",
    "#Excluding years prior to 2002 2020 and 2021 since we don't have forecast data. We also exclude years 2018, 2019 from law file because we need 2 years after and we have data\n",
    "#up to 2019\n",
    "filtered_df = df[~df['Year'].isin([1986, 1987, 1988, 1989,1990, 1991, 1992, 1993, 1994, 1995, 1996,\n",
    "                                   1997, 1998, 1999, 2000, 2001,2018, 2019, 2020, 2021, 2022, 2023, 2024])]\n",
    "\n",
    "filtered_df_with_titles = filtered_df.dropna(subset=[\"Regulatory Body\"])\n",
    "\n",
    "filtered_df_with_titles.to_csv('enter file path here')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7429c937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code adapted for Google Gemini API\n",
    "#Note: the code will run best when executing each section separately\n",
    "\n",
    "# 1. Gemini identify federal securities laws\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from typing import List, Dict\n",
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Gemini client + conversation helpers\n",
    "# ---------------------------\n",
    "#this function is needed for follow-up prompts otherwise gemini will not remember the converstation \n",
    "def _to_gemini_history(conv_hist):\n",
    "    \"\"\"\n",
    "    Convert OpenAI-style:\n",
    "      [{\"role\":\"user\"|\"assistant\", \"content\":\"...\"}]\n",
    "    to Gemini chat history:\n",
    "      [{\"role\":\"user\"|\"model\", \"parts\":[ \"...\"]}, ...]\n",
    "    \"\"\"\n",
    "    if not conv_hist:\n",
    "        return []\n",
    "    role_map = {\"user\": \"user\", \"assistant\": \"model\"}\n",
    "    history = []\n",
    "    for m in conv_hist:\n",
    "        r = role_map.get(m.get(\"role\"), \"user\")\n",
    "        history.append({\"role\": r, \"parts\": [m.get(\"content\", \"\")]})\n",
    "    return history\n",
    "\n",
    "\n",
    "def get_securities_laws(conversation_history=None):\n",
    "    # Configure Gemini with your API key \n",
    "    genai.configure(api_key=\"enter API here\")  \n",
    "\n",
    "    # Initial prompt \n",
    "    initial_content = \"\"\"Your task is to identify and compile a comprehensive database of at least 100 federal securities \n",
    "    laws. Securities regulation is the field of U.S. law that covers transactions and other dealings with securities. \n",
    "    Securities laws aim at ensuring that investors receive accurate and necessary information regarding the type and value\n",
    "    of the interest under consideration for purchase.\n",
    "\n",
    "IMPORTANT: Only identify new securities regulations. Exclude amendments, updates, or revisions to existing rules. \n",
    "Focus on major new laws only.\n",
    "\n",
    "IMPORTANT: Do not include laws with titles containing the following words: \"Amendment\", \"Update\", or \"Revision\"\n",
    "\n",
    "The goal is to create a dataset that captures the following key details for each law. \n",
    "\n",
    "Please follow these guidelines:\n",
    "\n",
    "Data Fields to Collect:\n",
    "• Date: The announcement or implementation date of the law (use YYYY-MM-DD format).\n",
    "• Regulation Title or Name: The official name or designation of the regulatory change.\n",
    "• Regulatory Body/Authority: The government entity responsible for the law.\n",
    "• Description: A brief overview of the law, including key provisions and the rationale behind it.\n",
    "• Impact: The potential or observed effects on industries, markets, or stakeholders.\n",
    "•Litigation Risk: Is this law related to the risk of litigation against managers? By risk of litigation we mean the probability that a manager will be sued or face legal action because of this law. Answer this question with Yes or No. If yes, label the entry \"Litigation Risk\".\n",
    "•Corporate Governance: Is this law related to corporate governance of firms? Corporate governance refers to the internal monitoring system charged with overseeing managers and commonly focuses on matters such as board independence or insider trading policy. Answer this question with Yes or No.If yes, label the entry \"Corporate Governance\".\n",
    "•Proprietary Costs: Is this law related to proprietary costs of firms? By proprietary costs, we mean costs that result from the disclosure of information to competitors which could harm a firm's competitive position. Answer this question with Yes or No.If yes, label the entry \"Proprietary Costs\".\n",
    "•Information Asymmetry: Is this law related to information asymmetry between owners and managers? By information asymmetry we mean that one party has more or better information than the other party. Answer this question with Yes or No. If yes, label the entry \"Information Asymmetry\".\n",
    "•Unsophisticated Investors: Is the law related to protecting unsophisticated investors? By unsophisticated investors, we mean investors that are either new to investing or are not well informed. Answer this question with Yes or No. If yes, label the entry \"Unsophisticated Investors\".\n",
    "•Equity Issuance in Public vs. Private Markets: Is this law related to the costs and benefits of issuing equity in public versus private markets? Answer this question with Yes or No. If yes, label the entry \"Equity Issuance in Public vs. Private Markets\".\n",
    "•Reputation Risk: Is this law related to the reputation of firm managers? By of firm manager, we mean the career prospects and prestige of an individual manager. Answer this question with Yes or No. If yes, label the entry \"Reputation Risk\".\n",
    "\n",
    "• References: Links to official documents or credible news sources.\n",
    "\n",
    "Requirements:\n",
    "• Scope: Cover as many laws as possible that were announced or implemented in the last 25 years.\n",
    "• Consistency: Ensure uniform formatting for all entries in the dataset.\n",
    "• Dates must be in YYYY-MM-DD format (e.g., 2002-07-30).\n",
    "\n",
    "Output:\n",
    "Provide data in a tabular format with rows for each law and columns for the data fields listed above. \n",
    "Use credible, authoritative sources such as government websites, legal databases, academic journals, or credible news sources.\n",
    "Do not include duplicate laws.\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        model = genai.GenerativeModel(\"gemini-2.5-pro\")\n",
    "        generation_config = {\n",
    "            \"temperature\": 0.5,\n",
    "            \"max_output_tokens\": 8000,\n",
    "        }\n",
    "\n",
    "        if conversation_history:\n",
    "            # ---- EDIT 1: send the latest user prompt, not empty content ----\n",
    "            last_user_msg = \"\"\n",
    "            if conversation_history and conversation_history[-1].get(\"role\") == \"user\":\n",
    "                last_user_msg = conversation_history[-1].get(\"content\", \"\")\n",
    "                history_without_last = conversation_history[:-1]\n",
    "            else:\n",
    "                history_without_last = conversation_history\n",
    "\n",
    "            chat = model.start_chat(history=_to_gemini_history(history_without_last))\n",
    "            print(\"Making API call to Gemini (chat.send_message)...\")\n",
    "            if not last_user_msg:\n",
    "                last_user_msg = \"Continue.\"\n",
    "            resp = chat.send_message(last_user_msg, generation_config=generation_config)\n",
    "\n",
    "            response_content = getattr(resp, \"text\", \"\") or \"\"\n",
    "            print(f\"Raw response object: {resp}\")\n",
    "            print(f\"Response content type: {type(response_content)}\")\n",
    "            print(f\"Response content: {repr(response_content)}\")\n",
    "            print(f\"API call successful! Response length: {len(response_content)} characters\")\n",
    "\n",
    "            updated_history = conversation_history + [{\"role\": \"assistant\", \"content\": response_content}]\n",
    "            return response_content, updated_history\n",
    "\n",
    "        else:\n",
    "            # First turn (no history yet)\n",
    "            print(\"Making API call to Gemini (generate_content)...\")\n",
    "            resp = model.generate_content(initial_content, generation_config=generation_config)\n",
    "            response_content = getattr(resp, \"text\", \"\") or \"\"\n",
    "            print(f\"Raw response object: {resp}\")\n",
    "            print(f\"Response content type: {type(response_content)}\")\n",
    "            print(f\"Response content: {repr(response_content)}\")\n",
    "            print(f\"API call successful! Response length: {len(response_content)} characters\")\n",
    "            messages = [\n",
    "                {\"role\": \"user\", \"content\": initial_content},\n",
    "                {\"role\": \"assistant\", \"content\": response_content},\n",
    "            ]\n",
    "            return response_content, messages\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error making Gemini API call: {e}\")\n",
    "        return None, conversation_history if conversation_history else []\n",
    "\n",
    "\n",
    "def add_follow_up_prompt(conversation_history, follow_up_prompt):\n",
    "    \"\"\"Add a follow-up prompt to the conversation history\"\"\"\n",
    "    return conversation_history + [{\"role\": \"user\", \"content\": follow_up_prompt}]\n",
    "\n",
    "\n",
    "def standardize_date(date_str):\n",
    "    \"\"\"Attempt to standardize date format to YYYY-MM-DD\"\"\"\n",
    "    try:\n",
    "        return pd.to_datetime(date_str).strftime('%Y-%m-%d')\n",
    "    except Exception:\n",
    "        return date_str\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Parsers\n",
    "# ---------------------------\n",
    "\n",
    "def parse_table_fallback(response_text: str) -> pd.DataFrame:\n",
    "    \"\"\"Fallback parser for when the model returns a Markdown table.\"\"\"\n",
    "    print(\"Debugging table parsing...\")\n",
    "\n",
    "    lines = response_text.split('\\n')\n",
    "    table_lines = [line.strip() for line in lines if line.strip().startswith('|') and len(line.strip()) > 5]\n",
    "\n",
    "    print(f\"Found {len(table_lines)} table lines\")\n",
    "\n",
    "    if len(table_lines) < 2:\n",
    "        print(\"Not enough table lines found\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Remove separator lines (containing ---)\n",
    "    data_lines = [line for line in table_lines if '---' not in line]\n",
    "    print(f\"Found {len(data_lines)} data lines (after removing separators)\")\n",
    "\n",
    "    if len(data_lines) < 2:\n",
    "        print(\"Not enough data lines after removing separators\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Parse header line\n",
    "    header_line = data_lines[0]\n",
    "    raw_headers = header_line.split('|')\n",
    "    headers = [col.strip() for col in raw_headers if col.strip()]\n",
    "\n",
    "    print(f\"Original headers ({len(headers)}): {headers}\")\n",
    "\n",
    "    # Parse data rows\n",
    "    data_rows = []\n",
    "    for i, line in enumerate(data_lines[1:], 1):\n",
    "        raw_columns = line.split('|')\n",
    "        columns = [col.strip() for col in raw_columns if col.strip()]\n",
    "        if len(columns) == len(headers):\n",
    "            data_rows.append(columns)\n",
    "            print(f\"Row {i}: ✓ Added ({len(columns)} columns)\")\n",
    "        else:\n",
    "            print(f\"Row {i}: ✗ Skipped - {len(columns)} columns vs {len(headers)} headers\")\n",
    "\n",
    "    print(f\"Successfully parsed {len(data_rows)} data rows\")\n",
    "\n",
    "    if not data_rows:\n",
    "        print(\"No valid data rows found\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df = pd.DataFrame(data_rows, columns=headers)\n",
    "    print(f\"Created DataFrame with columns: {list(df.columns)}\")\n",
    "\n",
    "    # ---- EDIT 2: Standardize column names (add 'Regulation Title or Name' and fallback copy) ----\n",
    "    standard_columns = {\n",
    "        'Date': 'Date',\n",
    "        'Regulation Title/Name': 'Regulation Title',\n",
    "        'Regulation Title or Name': 'Regulation Title',  # new variant\n",
    "        'Regulatory Body': 'Regulatory Body',\n",
    "        'Regulatory Body/Authority': 'Regulatory Body',\n",
    "        'Description': 'Description',\n",
    "        'Impact': 'Impact',\n",
    "        'Litigation Risk': 'Litigation Risk',\n",
    "        'Corporate Governance': 'Corporate Governance',\n",
    "        'Proprietary Costs': 'Proprietary Costs',\n",
    "        'Information Asymmetry': 'Information Asymmetry',\n",
    "        'Unsophisticated Investors': 'Unsophisticated Investors',\n",
    "        'Equity Issuance Public vs Private': 'Equity Issuance',\n",
    "        'Equity Issuance in Public vs. Private Markets': 'Equity Issuance',\n",
    "        'Reputation Risk': 'Reputation Risk',\n",
    "        'References': 'References'\n",
    "    }\n",
    "\n",
    "    df_renamed = df.rename(columns=standard_columns)\n",
    "\n",
    "    # If \"Regulation Title\" still missing, copy from any plausible original header\n",
    "    if 'Regulation Title' not in df_renamed.columns:\n",
    "        for alt in ['Regulation Title or Name', 'Regulation Title/Name', 'Regulation']:\n",
    "            if alt in df.columns:\n",
    "                df_renamed['Regulation Title'] = df[alt]\n",
    "                break\n",
    "\n",
    "    required_columns = [\n",
    "        'Date', 'Regulation Title', 'Regulatory Body', 'Description', 'Impact',\n",
    "        'Litigation Risk', 'Corporate Governance', 'Proprietary Costs',\n",
    "        'Information Asymmetry', 'Unsophisticated Investors', 'Equity Issuance',\n",
    "        'Reputation Risk', 'References'\n",
    "    ]\n",
    "\n",
    "    for col in required_columns:\n",
    "        if col not in df_renamed.columns:\n",
    "            print(f\"Adding missing column: {col}\")\n",
    "            df_renamed[col] = None\n",
    "\n",
    "    final_df = df_renamed[required_columns].copy()\n",
    "\n",
    "    # Standardize date format\n",
    "    if 'Date' in final_df.columns:\n",
    "        print(\"Standardizing dates...\")\n",
    "        final_df['Date'] = final_df['Date'].apply(\n",
    "            lambda x: standardize_date(x) if pd.notna(x) and str(x).strip() else x\n",
    "        )\n",
    "\n",
    "    final_df = final_df.dropna(how='all')\n",
    "\n",
    "    print(f\"Final DataFrame: {len(final_df)} rows x {len(final_df.columns)} columns\")\n",
    "    print(f\"Final columns: {list(final_df.columns)}\")\n",
    "\n",
    "    return final_df\n",
    "\n",
    "\n",
    "def parse_bullet_format(response_text: str) -> pd.DataFrame:\n",
    "    \"\"\"Parse response in numbered + markdown bullet format.\"\"\"\n",
    "    entries = []\n",
    "    current_entry = {}\n",
    "    entry_number = None\n",
    "\n",
    "    lines = [line.strip() for line in response_text.split(\"\\n\") if line.strip()]\n",
    "\n",
    "    for line in lines:\n",
    "        # Detect new numbered law like \"4.\" or \"12.\"\n",
    "        number_match = re.match(r'^(\\d+)\\.', line)\n",
    "        if number_match:\n",
    "            if current_entry:\n",
    "                entries.append(current_entry)\n",
    "            current_entry = {}\n",
    "            entry_number = number_match.group(1)\n",
    "            continue\n",
    "\n",
    "        # Detect bullet fields like \"- **Date**: 1996-10-11\"\n",
    "        bullet_match = re.match(r'^-\\s*\\*\\*(.+?)\\*\\*:\\s*(.+)', line)\n",
    "        if bullet_match and current_entry is not None:\n",
    "            key, value = bullet_match.groups()\n",
    "            key = key.strip()\n",
    "            value = value.strip()\n",
    "\n",
    "            key_mapping = {\n",
    "                \"Date\": \"Date\",\n",
    "                \"Title\": \"Regulation Title\",\n",
    "                \"Authority\": \"Regulatory Body\",\n",
    "                \"Description\": \"Description\",\n",
    "                \"Impact\": \"Impact\",\n",
    "                \"Litigation Risk\": \"Litigation Risk\",\n",
    "                \"Corporate Governance\": \"Corporate Governance\",\n",
    "                \"Proprietary Costs\": \"Proprietary Costs\",\n",
    "                \"Information Asymmetry\": \"Information Asymmetry\",\n",
    "                \"Unsophisticated Investors\": \"Unsophisticated Investors\",\n",
    "                \"Equity Issuance\": \"Equity Issuance\",\n",
    "                \"Reputation Risk\": \"Reputation Risk\",\n",
    "                \"References\": \"References\"\n",
    "            }\n",
    "\n",
    "            if key in key_mapping:\n",
    "                current_entry[key_mapping[key]] = value\n",
    "\n",
    "    if current_entry:\n",
    "        entries.append(current_entry)\n",
    "\n",
    "    if not entries:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df = pd.DataFrame(entries)\n",
    "\n",
    "    required_columns = [\n",
    "        'Date', 'Regulation Title', 'Regulatory Body', 'Description', 'Impact',\n",
    "        'Litigation Risk', 'Corporate Governance', 'Proprietary Costs',\n",
    "        'Information Asymmetry', 'Unsophisticated Investors', 'Equity Issuance',\n",
    "        'Reputation Risk', 'References'\n",
    "    ]\n",
    "    for col in required_columns:\n",
    "        if col not in df.columns:\n",
    "            df[col] = None\n",
    "\n",
    "    return df[required_columns]\n",
    "\n",
    "\n",
    "def parse_response_to_dataframe(response_text: str) -> pd.DataFrame:\n",
    "    \"\"\"Parse the response text into a pandas DataFrame.\"\"\"\n",
    "    print(\"\\nParsing response...\")\n",
    "    \n",
    "    # First try the updated bold markdown format parsing\n",
    "    data = []\n",
    "    current_entry = None\n",
    "    entry_number = None\n",
    "    \n",
    "    lines = [line.strip() for line in response_text.split('\\n') if line.strip()]\n",
    "    \n",
    "    for line in lines:\n",
    "        # Updated regex to handle bold markdown format: **24.**\n",
    "        number_match = re.match(r'^\\*\\*(\\d+)\\.\\*\\*', line)\n",
    "        if number_match:\n",
    "            if current_entry and len(current_entry) > 0:\n",
    "                if 'Regulation Title' not in current_entry and entry_number:\n",
    "                    current_entry['Regulation Title'] = f\"Law {entry_number}\"\n",
    "                data.append(current_entry)\n",
    "            current_entry = {}\n",
    "            entry_number = number_match.group(1)\n",
    "            continue\n",
    "            \n",
    "        # Updated to handle bold markdown fields: **Date:** value\n",
    "        if ':' in line and current_entry is not None:\n",
    "            # Handle both **Field:** and Field: formats\n",
    "            if line.startswith('**') and ':**' in line:\n",
    "                # Bold markdown format: **Date:** value\n",
    "                key_value = line.split(':**', 1)\n",
    "                key = key_value[0].replace('**', '').strip()\n",
    "                value = key_value[1].strip() if len(key_value) > 1 else ''\n",
    "            elif ':' in line:\n",
    "                # Regular format: Date: value\n",
    "                key, value = [x.strip() for x in line.split(':', 1)]\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "            key_mapping = {\n",
    "                'Date': 'Date',\n",
    "                'Title': 'Regulation Title',\n",
    "                'Authority': 'Regulatory Body',\n",
    "                'Description': 'Description',\n",
    "                'Impact': 'Impact',\n",
    "                'Litigation Risk': 'Litigation Risk',\n",
    "                'Corporate Governance': 'Corporate Governance',\n",
    "                'Proprietary Costs': 'Proprietary Costs',\n",
    "                'Information Asymmetry': 'Information Asymmetry',\n",
    "                'Unsophisticated Investors': 'Unsophisticated Investors',\n",
    "                'Equity Issuance': 'Equity Issuance',\n",
    "                'Equity Issuance in Public vs. Private Markets': 'Equity Issuance',\n",
    "                'Reputation Risk': 'Reputation Risk',\n",
    "                'References': 'References'\n",
    "            }\n",
    "            \n",
    "            if key in key_mapping:\n",
    "                column_name = key_mapping[key]\n",
    "                if column_name == 'Date':\n",
    "                    current_entry[column_name] = standardize_date(value)\n",
    "                else:\n",
    "                    current_entry[column_name] = value.strip()\n",
    "\n",
    "    # Add the last entry\n",
    "    if current_entry and len(current_entry) > 0:\n",
    "        if 'Regulation Title' not in current_entry and entry_number:\n",
    "            current_entry['Regulation Title'] = f\"Law {entry_number}\"\n",
    "        data.append(current_entry)\n",
    "\n",
    "    print(f\"\\nFound {len(data)} entries in bold markdown format\")\n",
    "\n",
    "    if data:\n",
    "        df = pd.DataFrame(data)\n",
    "        required_columns = [\n",
    "            'Date', 'Regulation Title', 'Regulatory Body', 'Description', 'Impact',\n",
    "            'Litigation Risk', 'Corporate Governance', 'Proprietary Costs',\n",
    "            'Information Asymmetry', 'Unsophisticated Investors', 'Equity Issuance',\n",
    "            'Reputation Risk', 'References'\n",
    "        ]\n",
    "        for col in required_columns:\n",
    "            if col not in df.columns:\n",
    "                print(f\"Adding missing column: {col}\")\n",
    "                df[col] = None\n",
    "        df['Regulation Title'] = df['Regulation Title'].fillna('Unknown')\n",
    "        df['Regulation Title'] = df['Regulation Title'].apply(lambda x: re.sub(r'\\s+', ' ', x).strip())\n",
    "        df['dedup_key'] = df.apply(lambda row: f\"{row['Date']}_{row['Regulation Title']}\", axis=1)\n",
    "        df = df.drop_duplicates(subset=['dedup_key'], keep='first')\n",
    "        df = df.drop('dedup_key', axis=1)\n",
    "        df = df[required_columns]\n",
    "        print(f\"Created DataFrame with {len(df)} rows\")\n",
    "        return df.copy()\n",
    "\n",
    "    # If bold markdown format failed, try table format\n",
    "    print(\"Bold markdown format parsing failed, trying table format...\")\n",
    "    df = parse_table_fallback(response_text)\n",
    "    if not df.empty:\n",
    "        print(f\"Table format parsing succeeded with {len(df)} rows\")\n",
    "        return df\n",
    "\n",
    "    # If table format failed, try bullet format\n",
    "    print(\"Table format parsing failed, trying bullet format...\")\n",
    "    df = parse_bullet_format(response_text)\n",
    "    if not df.empty:\n",
    "        print(f\"Bullet format parsing succeeded with {len(df)} rows\")\n",
    "        return df\n",
    "\n",
    "    # All methods failed\n",
    "    print(\"All parsing methods failed - no valid data to create DataFrame\")\n",
    "    print(\"\\nSample of model response (first 10 lines):\")\n",
    "    for i, line in enumerate(response_text.split(\"\\n\")[:10], 1):\n",
    "        print(f\"{i:02d}: {line}\")\n",
    "    return pd.DataFrame()\n",
    "\n",
    "# ---------------------------\n",
    "# Orchestration\n",
    "# ---------------------------\n",
    "\n",
    "def compile_all_responses() -> pd.DataFrame:\n",
    "    \"\"\"Compile multiple API responses into a single DataFrame.\"\"\"\n",
    "    all_responses = []\n",
    "    conversation_history = None\n",
    "\n",
    "    # Get initial response\n",
    "    initial_response, conversation_history = get_securities_laws()\n",
    "    if initial_response:\n",
    "        print(\"\\nInitial response:\")\n",
    "        print(\"=\"*50)\n",
    "        print(initial_response)\n",
    "        print(\"=\"*50)\n",
    "        print(f\"Response length: {len(initial_response)} characters\")\n",
    "        all_responses.append(initial_response)\n",
    "    else:\n",
    "        print(\"ERROR: No initial response received from API!\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Follow-up prompts for additional laws (unchanged)\n",
    "    follow_up_prompts = [\n",
    "        \"\"\"Starting with number {last_num}, list 20 more federal securities laws using this exact format for each:\n",
    "Date: YYYY-MM-DD\n",
    "Title: [title]\n",
    "Authority: [body]\n",
    "Description: [brief]\n",
    "Impact: [impact]\n",
    "Litigation Risk: Yes/No\n",
    "Corporate Governance: Yes/No\n",
    "Proprietary Costs: Yes/No\n",
    "Information Asymmetry: Yes/No\n",
    "Unsophisticated Investors: Yes/No\n",
    "Equity Issuance: Yes/No\n",
    "Reputation Risk: Yes/No\n",
    "References: [link]\"\"\",\n",
    "\n",
    "        \"Continue from number {last_num}. Provide 20 more laws using the exact same format.\",\n",
    "        \n",
    "        \"List 20 more laws starting at number {last_num}. Use the same format.\",\n",
    "        \n",
    "        \"Add 20 more laws beginning with number {last_num}. Keep the same format.\",\n",
    "        \n",
    "        \"Provide 20 more laws from number {last_num}. Same format.\",\n",
    "        \n",
    "        \"Recall that you have to identify at least 100 federal securities laws. Recall securities regulation is the field of U.S. law that covers transactions and other dealings with securities. Securities laws aim at ensuring that investors receive accurate and necessary information regarding the type and value of the interest under consideration for purchase.\"\n",
    "    ]\n",
    "    last_num = len(parse_response_to_dataframe(initial_response)) + 1\n",
    "\n",
    "    for i, prompt_template in enumerate(follow_up_prompts, 1):\n",
    "        prompt = prompt_template.format(last_num=last_num)\n",
    "        conversation_history = add_follow_up_prompt(conversation_history, prompt)\n",
    "        response, conversation_history = get_securities_laws(conversation_history)\n",
    "\n",
    "        if response:\n",
    "            print(f\"\\nFollow-up response {i}:\")\n",
    "            print(response)\n",
    "            all_responses.append(response)\n",
    "            df = parse_response_to_dataframe(response)\n",
    "            last_num += len(df)\n",
    "\n",
    "    # Parse all responses into DataFrames and concatenate\n",
    "    dfs = []\n",
    "    for response in all_responses:\n",
    "        df = parse_response_to_dataframe(response)\n",
    "        if not df.empty:\n",
    "            dfs.append(df)\n",
    "\n",
    "    if not dfs:\n",
    "        print(\"No valid data frames were created!\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Concatenate all DataFrames\n",
    "    final_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    # Remove duplicates using multiple fields to better identify unique laws\n",
    "    final_df['Title_clean'] = final_df['Regulation Title'].fillna('').str.lower().str.strip()\n",
    "    final_df['Description_clean'] = final_df['Description'].fillna('').str.lower().str.strip()\n",
    "\n",
    "    # Create composite key for deduplication\n",
    "    final_df['dedup_key'] = final_df.apply(\n",
    "        lambda row: f\"{row['Date']}_{row['Title_clean']}_{row['Description_clean'][:50]}\",\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    final_df = final_df.drop_duplicates(subset=['dedup_key'], keep='first')\n",
    "    final_df = final_df.drop(['Title_clean', 'Description_clean', 'dedup_key'], axis=1)\n",
    "\n",
    "    # Sort by date\n",
    "    try:\n",
    "        final_df['DateSort'] = pd.to_datetime(final_df['Date'], errors='coerce')\n",
    "        final_df = final_df.dropna(subset=['DateSort'])\n",
    "        final_df = final_df.sort_values('DateSort', ascending=False)\n",
    "        final_df = final_df.drop('DateSort', axis=1)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not sort by date due to: {e}\")\n",
    "        print(\"Problematic dates:\")\n",
    "        print(final_df['Date'].value_counts())\n",
    "\n",
    "    # Return the final DataFrame\n",
    "    return final_df\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Compile all responses into a DataFrame\n",
    "    df = compile_all_responses()\n",
    "\n",
    "    if df.empty:\n",
    "        print(\"\\nError: No data was collected!\")\n",
    "    else:\n",
    "        # Display basic statistics\n",
    "        print(f\"\\nTotal number of unique laws: {len(df)}\")\n",
    "        print(\"\\nMost recent laws:\")\n",
    "        print(df.head().to_string())\n",
    "\n",
    "        # Save to CSV (path can be changed as needed)\n",
    "        output_path = 'enter file path here'\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"\\nDatabase saved to: {output_path}\")\n",
    "        \n",
    "# 2. Add column for Year \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv('enter file path here')\n",
    "\n",
    "# Clean parentheses and dashes from text columns\n",
    "for column in df.select_dtypes(include=['object']).columns:\n",
    "    df[column] = df[column].str.replace('(', '').str.replace(')', '').str.replace('-', '')\n",
    "    \n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['Year'] = df['Date'].dt.year\n",
    "df\n",
    "\n",
    "#Excluding years prior to 2002 2020 and 2021 since we don't have forecast data. We also exclude years 2018, 2019 from law file because we need 2 years after and we have data\n",
    "#up to 2019\n",
    "filtered_df = df[~df['Year'].isin([1986, 1987, 1988, 1989,1990, 1991, 1992, 1993, 1994, 1995, 1996,\n",
    "                                   1997, 1998, 1999, 2000, 2001,2018, 2019, 2020, 2021, 2022, 2023, 2024])]\n",
    "\n",
    "filtered_df_with_titles = filtered_df.dropna(subset=[\"Regulatory Body\"])\n",
    "\n",
    "filtered_df_with_titles.to_csv('enter file path here')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
