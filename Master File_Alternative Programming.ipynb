{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa715180",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code was developed in collaboration with Claude4-Sonnet\n",
    "#Claude was used for code generation, documentation, and error handling\n",
    "#Note: the code will run best when executing each section separately\n",
    "\n",
    "# 1. Use Claude to generate code for empirical analysis\n",
    "\n",
    "import anthropic\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "API_KEY = \"enter API key here\"\n",
    "\n",
    "# Python Code Generation for Empirical Analysis\n",
    "prompt = \"\"\"You are an accounting academic. Your task is to generate Python code to conduct empirical analysis.\n",
    "Run multiple regression specifications with and without fixed effects.\n",
    "\n",
    "IMPORTANT: These regressions will be run for multiple panels from a directory.\n",
    " \n",
    "Follow these guidelines:\n",
    "-Write Python code to generate a time trend variable.\n",
    "-Write Python code to filter the data to ±2 years around regulation year.\n",
    "-Write Python code to generate 3 regression specifications:\n",
    "    For the first regression, this is baseline model, a univariate regression using ordinary least   squares (OLS) with no control variables\n",
    "    For the second regression, this is a model with control variables (including the time trend variable you just created)\n",
    "    For the third regression, this is a model with control variables and firm fixed effects\n",
    "-Each regression should  include standard errors clustered at the firm level.\n",
    "-Write Process all the CSV files in the directory.\n",
    "-Write Python code to save the regression results as a JSON file and as a PDF file.\n",
    "\n",
    "IMPORTANT: \n",
    "-The regulation year is stored in a column called 'Year' in the data.\n",
    "-The data has firm and year identifiers: 'GVKEY' and 'FYEAR'.\n",
    "-The independent variable is 'treatment_effect'.\n",
    "-The control variables are 'linstown', 'lsize', 'lbtm', 'lroa', 'lsaret12', 'levol', 'lloss', 'lcalrisk','time_trend'.\n",
    "-The dependent variable is 'freqMF'.\n",
    "-Include both coefficient estimates and t-stats in outputs. \n",
    "\"\"\"\n",
    "\n",
    "def call_claude_api(prompt, api_key, model=\"claude-sonnet-4-20250514\"):\n",
    "    \"\"\"\n",
    "    Send a prompt to Claude API and return the response\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = anthropic.Anthropic(api_key=api_key)\n",
    "        \n",
    "        message = client.messages.create(\n",
    "            model=model,\n",
    "            max_tokens=8000,  \n",
    "            temperature=0.5,    \n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        return message.content[0].text\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error calling Claude API: {e}\")\n",
    "        return None\n",
    "\n",
    "def save_response(response, filename=\"claude_response.txt\"):\n",
    "    \"\"\"\n",
    "    Save Claude's response to a file\n",
    "    \"\"\"\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(response)\n",
    "    print(f\"Response saved to {filename}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Sending prompt to Claude API...\")\n",
    "    response = call_claude_api(prompt, API_KEY)\n",
    "    \n",
    "    if response:\n",
    "        print(\"Response received!\")\n",
    "        print(\"-\" * 50)\n",
    "        print(response)\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Save the response\n",
    "        save_response(response, \"empirical_analysis_code.txt\")\n",
    "        if \"```python\" in response:\n",
    "            code_start = response.find(\"```python\") + len(\"```python\")\n",
    "            code_end = response.find(\"```\", code_start)\n",
    "            if code_end != -1:\n",
    "                python_code = response[code_start:code_end].strip()\n",
    "                with open(\"empirical_analysis.py\", 'w', encoding='utf-8') as f:\n",
    "                    f.write(python_code)\n",
    "                print(\"Python code extracted and saved to empirical_analysis.py\")\n",
    "    else:\n",
    "        print(\"Failed to get response from Claude API\")\n",
    "        \n",
    "# 2. Code below is from Claude (created above)\n",
    "#Copied and pasted in this box\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from linearmodels.panel import PanelOLS\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def generate_time_trend(df):\n",
    "    \"\"\"\n",
    "    Generate a time trend variable based on FYEAR\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    min_year = df['FYEAR'].min()\n",
    "    df['time_trend'] = df['FYEAR'] - min_year\n",
    "    return df\n",
    "\n",
    "def filter_data_around_regulation(df, window=2):\n",
    "    \"\"\"\n",
    "    Filter data to ±2 years around regulation year\n",
    "    Assumes regulation year is stored in 'Year' column\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # If 'Year' contains the regulation year for each observation\n",
    "    if 'Year' in df.columns:\n",
    "        df = df[(df['FYEAR'] >= df['Year'] - window) & \n",
    "                (df['FYEAR'] <= df['Year'] + window)]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def run_regression_specifications(df):\n",
    "    \"\"\"\n",
    "    Run three regression specifications with clustered standard errors\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # Ensure we have the required columns\n",
    "    required_cols = ['freqMF', 'treatment_effect', 'GVKEY', 'FYEAR']\n",
    "    control_vars = ['linstown', 'lsize', 'lbtm', 'lroa', 'lsaret12', \n",
    "                   'levol', 'lloss', 'lcalrisk', 'time_trend']\n",
    "    \n",
    "    # Check if all required columns exist\n",
    "    missing_cols = [col for col in required_cols + control_vars if col not in df.columns]\n",
    "    if missing_cols:\n",
    "        print(f\"Warning: Missing columns: {missing_cols}\")\n",
    "    \n",
    "    # Remove rows with missing values in key variables\n",
    "    key_vars = ['freqMF', 'treatment_effect', 'GVKEY', 'FYEAR']\n",
    "    df_clean = df.dropna(subset=key_vars)\n",
    "    \n",
    "    if len(df_clean) == 0:\n",
    "        print(\"No valid observations after cleaning\")\n",
    "        return results\n",
    "    \n",
    "    try:\n",
    "        # Specification 1: Baseline OLS (univariate)\n",
    "        formula1 = 'freqMF ~ treatment_effect'\n",
    "        model1 = ols(formula1, data=df_clean).fit(cov_type='cluster', \n",
    "                                                  cov_kwds={'groups': df_clean['GVKEY']})\n",
    "        \n",
    "        results['spec1_baseline'] = {\n",
    "            'formula': formula1,\n",
    "            'n_obs': int(model1.nobs),\n",
    "            'r_squared': float(model1.rsquared),\n",
    "            'coefficients': {},\n",
    "            't_stats': {},\n",
    "            'p_values': {},\n",
    "            'std_errors': {}\n",
    "        }\n",
    "        \n",
    "        for var in model1.params.index:\n",
    "            results['spec1_baseline']['coefficients'][var] = float(model1.params[var])\n",
    "            results['spec1_baseline']['t_stats'][var] = float(model1.tvalues[var])\n",
    "            results['spec1_baseline']['p_values'][var] = float(model1.pvalues[var])\n",
    "            results['spec1_baseline']['std_errors'][var] = float(model1.bse[var])\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in Specification 1: {e}\")\n",
    "        results['spec1_baseline'] = {'error': str(e)}\n",
    "    \n",
    "    try:\n",
    "        # Specification 2: OLS with control variables\n",
    "        available_controls = [var for var in control_vars if var in df_clean.columns]\n",
    "        control_formula = ' + '.join(available_controls)\n",
    "        formula2 = f'freqMF ~ treatment_effect + {control_formula}'\n",
    "        \n",
    "        # Remove rows with missing control variables\n",
    "        all_vars = ['freqMF', 'treatment_effect'] + available_controls\n",
    "        df_spec2 = df_clean.dropna(subset=all_vars)\n",
    "        \n",
    "        if len(df_spec2) > 0:\n",
    "            model2 = ols(formula2, data=df_spec2).fit(cov_type='cluster', \n",
    "                                                      cov_kwds={'groups': df_spec2['GVKEY']})\n",
    "            \n",
    "            results['spec2_controls'] = {\n",
    "                'formula': formula2,\n",
    "                'n_obs': int(model2.nobs),\n",
    "                'r_squared': float(model2.rsquared),\n",
    "                'coefficients': {},\n",
    "                't_stats': {},\n",
    "                'p_values': {},\n",
    "                'std_errors': {}\n",
    "            }\n",
    "            \n",
    "            for var in model2.params.index:\n",
    "                results['spec2_controls']['coefficients'][var] = float(model2.params[var])\n",
    "                results['spec2_controls']['t_stats'][var] = float(model2.tvalues[var])\n",
    "                results['spec2_controls']['p_values'][var] = float(model2.pvalues[var])\n",
    "                results['spec2_controls']['std_errors'][var] = float(model2.bse[var])\n",
    "        else:\n",
    "            results['spec2_controls'] = {'error': 'No observations after removing missing values'}\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in Specification 2: {e}\")\n",
    "        results['spec2_controls'] = {'error': str(e)}\n",
    "    \n",
    "    try:\n",
    "        # Specification 3: Panel regression with firm fixed effects\n",
    "        available_controls = [var for var in control_vars if var in df_clean.columns]\n",
    "        all_vars = ['freqMF', 'treatment_effect'] + available_controls + ['GVKEY', 'FYEAR']\n",
    "        df_spec3 = df_clean.dropna(subset=all_vars)\n",
    "        \n",
    "        if len(df_spec3) > 0:\n",
    "            # Set up panel data\n",
    "            df_spec3 = df_spec3.set_index(['GVKEY', 'FYEAR'])\n",
    "            \n",
    "            # Prepare variables for panel regression\n",
    "            y = df_spec3['freqMF']\n",
    "            X_vars = ['treatment_effect'] + available_controls\n",
    "            X = df_spec3[X_vars]\n",
    "            \n",
    "            # Run panel regression with entity fixed effects\n",
    "            model3 = PanelOLS(y, X, entity_effects=True).fit(cov_type='clustered', \n",
    "                                                              cluster_entity=True)\n",
    "            \n",
    "            results['spec3_fixed_effects'] = {\n",
    "                'n_obs': int(model3.nobs),\n",
    "                'r_squared': float(model3.rsquared),\n",
    "                'coefficients': {},\n",
    "                't_stats': {},\n",
    "                'p_values': {},\n",
    "                'std_errors': {}\n",
    "            }\n",
    "            \n",
    "            for var in model3.params.index:\n",
    "                results['spec3_fixed_effects']['coefficients'][var] = float(model3.params[var])\n",
    "                results['spec3_fixed_effects']['t_stats'][var] = float(model3.tstats[var])\n",
    "                results['spec3_fixed_effects']['p_values'][var] = float(model3.pvalues[var])\n",
    "                results['spec3_fixed_effects']['std_errors'][var] = float(model3.std_errors[var])\n",
    "        else:\n",
    "            results['spec3_fixed_effects'] = {'error': 'No observations after removing missing values'}\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in Specification 3: {e}\")\n",
    "        results['spec3_fixed_effects'] = {'error': str(e)}\n",
    "    \n",
    "    return results\n",
    "\n",
    "def create_results_table_pdf(all_results, output_path):\n",
    "    \"\"\"\n",
    "    Create a PDF with regression results tables\n",
    "    \"\"\"\n",
    "    with PdfPages(output_path) as pdf:\n",
    "        for file_name, results in all_results.items():\n",
    "            fig, ax = plt.subplots(figsize=(12, 8))\n",
    "            ax.axis('tight')\n",
    "            ax.axis('off')\n",
    "            \n",
    "            # Create table data\n",
    "            table_data = []\n",
    "            headers = ['Variable', 'Spec 1: Baseline', 'Spec 2: Controls', 'Spec 3: Fixed Effects']\n",
    "            table_data.append(headers)\n",
    "            \n",
    "            # Get all variables across specifications\n",
    "            all_vars = set()\n",
    "            for spec_name in ['spec1_baseline', 'spec2_controls', 'spec3_fixed_effects']:\n",
    "                if spec_name in results and 'coefficients' in results[spec_name]:\n",
    "                    all_vars.update(results[spec_name]['coefficients'].keys())\n",
    "            \n",
    "            # Add coefficient and t-stat rows for each variable\n",
    "            for var in sorted(all_vars):\n",
    "                if var == 'Intercept':\n",
    "                    continue\n",
    "                    \n",
    "                coef_row = [var]\n",
    "                tstat_row = ['']\n",
    "                \n",
    "                for spec_name in ['spec1_baseline', 'spec2_controls', 'spec3_fixed_effects']:\n",
    "                    if (spec_name in results and \n",
    "                        'coefficients' in results[spec_name] and \n",
    "                        var in results[spec_name]['coefficients']):\n",
    "                        \n",
    "                        coef = results[spec_name]['coefficients'][var]\n",
    "                        tstat = results[spec_name]['t_stats'][var]\n",
    "                        pval = results[spec_name]['p_values'][var]\n",
    "                        \n",
    "                        # Add significance stars\n",
    "                        stars = ''\n",
    "                        if pval < 0.01:\n",
    "                            stars = '***'\n",
    "                        elif pval < 0.05:\n",
    "                            stars = '**'\n",
    "                        elif pval < 0.10:\n",
    "                            stars = '*'\n",
    "                        \n",
    "                        coef_row.append(f'{coef:.4f}{stars}')\n",
    "                        tstat_row.append(f'({tstat:.2f})')\n",
    "                    else:\n",
    "                        coef_row.append('')\n",
    "                        tstat_row.append('')\n",
    "                \n",
    "                table_data.append(coef_row)\n",
    "                table_data.append(tstat_row)\n",
    "            \n",
    "            # Add summary statistics\n",
    "            table_data.append([''])\n",
    "            obs_row = ['Observations']\n",
    "            r2_row = ['R-squared']\n",
    "            \n",
    "            for spec_name in ['spec1_baseline', 'spec2_controls', 'spec3_fixed_effects']:\n",
    "                if spec_name in results and 'n_obs' in results[spec_name]:\n",
    "                    obs_row.append(str(results[spec_name]['n_obs']))\n",
    "                    r2_row.append(f\"{results[spec_name]['r_squared']:.4f}\")\n",
    "                else:\n",
    "                    obs_row.append('')\n",
    "                    r2_row.append('')\n",
    "            \n",
    "            table_data.append(obs_row)\n",
    "            table_data.append(r2_row)\n",
    "            \n",
    "            # Create table\n",
    "            table = ax.table(cellText=table_data, cellLoc='center', loc='center')\n",
    "            table.auto_set_font_size(False)\n",
    "            table.set_fontsize(8)\n",
    "            table.scale(1.2, 1.5)\n",
    "            \n",
    "            # Style the table\n",
    "            for i in range(len(headers)):\n",
    "                table[(0, i)].set_facecolor('#40466e')\n",
    "                table[(0, i)].set_text_props(weight='bold', color='white')\n",
    "            \n",
    "            plt.title(f'Regression Results: {file_name}', fontsize=14, fontweight='bold', pad=20)\n",
    "            pdf.savefig(fig, bbox_inches='tight')\n",
    "            plt.close()\n",
    "\n",
    "def main():\n",
    "    # Set directory path containing CSV files\n",
    "    data_directory = \"enter file path here\"\n",
    "    if not data_directory:\n",
    "        data_directory = \".\"  # Current directory if no input\n",
    "    \n",
    "    # Output directory\n",
    "    output_dir = \"regression_results\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Check where files are saved\n",
    "    print(f\"Results will be saved to: {os.path.abspath(output_dir)}\")\n",
    "    \n",
    "    # Dictionary to store all results\n",
    "    all_results = {}\n",
    "    \n",
    "    # Process all CSV files in the directory\n",
    "    csv_files = list(Path(data_directory).glob(\"*.csv\"))\n",
    "    \n",
    "    if not csv_files:\n",
    "        print(f\"No CSV files found in {data_directory}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(csv_files)} CSV files to process\")\n",
    "    \n",
    "    for csv_file in csv_files:\n",
    "        print(f\"\\nProcessing: {csv_file.name}\")\n",
    "        \n",
    "        try:\n",
    "            # Read the data\n",
    "            df = pd.read_csv(csv_file)\n",
    "            print(f\"Loaded {len(df)} observations\")\n",
    "            \n",
    "            # Generate time trend variable\n",
    "            df = generate_time_trend(df)\n",
    "            \n",
    "            # Filter data to ±2 years around regulation year\n",
    "            df_filtered = filter_data_around_regulation(df, window=2)\n",
    "            print(f\"After filtering: {len(df_filtered)} observations\")\n",
    "            \n",
    "            if len(df_filtered) == 0:\n",
    "                print(\"No observations after filtering\")\n",
    "                continue\n",
    "            \n",
    "            # Run regression specifications\n",
    "            results = run_regression_specifications(df_filtered)\n",
    "            \n",
    "            # Store results\n",
    "            all_results[csv_file.stem] = results\n",
    "            \n",
    "            print(f\"Completed analysis for {csv_file.name}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {csv_file.name}: {e}\")\n",
    "            all_results[csv_file.stem] = {'error': str(e)}\n",
    "    \n",
    "    # Save results as JSON\n",
    "    json_output = os.path.join(output_dir, \"regression_results.json\")\n",
    "    with open(json_output, 'w') as f:\n",
    "        json.dump(all_results, f, indent=2)\n",
    "    print(f\"\\nResults saved to: {json_output}\")\n",
    "    \n",
    "    # Create PDF with results tables\n",
    "    pdf_output = os.path.join(output_dir, \"regression_results.pdf\")\n",
    "    create_results_table_pdf(all_results, pdf_output)\n",
    "    print(f\"PDF report saved to: {pdf_output}\")\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\nSummary:\")\n",
    "    print(f\"- Processed {len(csv_files)} files\")\n",
    "    print(f\"- Successful analyses: {len([r for r in all_results.values() if 'error' not in r])}\")\n",
    "    print(f\"- Results saved in: {output_dir}/\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "# 3. Using Claude to fix the error from the Python code it created \n",
    "\n",
    "import anthropic\n",
    "import os\n",
    "\n",
    "\n",
    "API_KEY = \"enter API key here\"\n",
    "\n",
    "# Error-fixing prompt\n",
    "prompt = \"\"\"I have Python code that runs empirical analysis and creates regression tables. The script successfully \n",
    "creates JSON output but fails when creating the PDF table with this error:\n",
    "\n",
    "Here's the current `create_results_table_pdf` function that needs to be fixed:\n",
    "\n",
    "def create_results_table_pdf(all_results, output_path):\n",
    "\n",
    "    with PdfPages(output_path) as pdf:\n",
    "        for file_name, results in all_results.items():\n",
    "            fig, ax = plt.subplots(figsize=(12, 8))\n",
    "            ax.axis('tight')\n",
    "            ax.axis('off')\n",
    "            \n",
    "            # Create table data\n",
    "            table_data = []\n",
    "            headers = ['Variable', 'Spec 1: Baseline', 'Spec 2: Controls', 'Spec 3: Fixed Effects']\n",
    "            table_data.append(headers)\n",
    "            \n",
    "            # Get all variables across specifications\n",
    "            all_vars = set()\n",
    "            for spec_name in ['spec1_baseline', 'spec2_controls', 'spec3_fixed_effects']:\n",
    "                if spec_name in results and 'coefficients' in results[spec_name]:\n",
    "                    all_vars.update(results[spec_name]['coefficients'].keys())\n",
    "            \n",
    "            # Add coefficient and t-stat rows for each variable\n",
    "            for var in sorted(all_vars):\n",
    "                if var == 'Intercept':\n",
    "                    continue\n",
    "                    \n",
    "                coef_row = [var]\n",
    "                tstat_row = ['']\n",
    "                \n",
    "                for spec_name in ['spec1_baseline', 'spec2_controls', 'spec3_fixed_effects']:\n",
    "                    if (spec_name in results and \n",
    "                        'coefficients' in results[spec_name] and \n",
    "                        var in results[spec_name]['coefficients']):\n",
    "                        \n",
    "                        coef = results[spec_name]['coefficients'][var]\n",
    "                        tstat = results[spec_name]['t_stats'][var]\n",
    "                        pval = results[spec_name]['p_values'][var]\n",
    "                        \n",
    "                        # Add significance stars\n",
    "                        stars = ''\n",
    "                        if pval < 0.01:\n",
    "                            stars = '***'\n",
    "                        elif pval < 0.05:\n",
    "                            stars = '**'\n",
    "                        elif pval < 0.10:\n",
    "                            stars = '*'\n",
    "                        \n",
    "                        coef_row.append(f'{coef:.4f}{stars}')\n",
    "                        tstat_row.append(f'({tstat:.2f})')\n",
    "                    else:\n",
    "                        coef_row.append('')\n",
    "                        tstat_row.append('')\n",
    "                \n",
    "                table_data.append(coef_row)\n",
    "                table_data.append(tstat_row)\n",
    "            \n",
    "            # Add summary statistics\n",
    "            table_data.append([''])\n",
    "            obs_row = ['Observations']\n",
    "            r2_row = ['R-squared']\n",
    "            \n",
    "            for spec_name in ['spec1_baseline', 'spec2_controls', 'spec3_fixed_effects']:\n",
    "                if spec_name in results and 'n_obs' in results[spec_name]:\n",
    "                    obs_row.append(str(results[spec_name]['n_obs']))\n",
    "                    r2_row.append(f\"{results[spec_name]['r_squared']:.4f}\")\n",
    "                else:\n",
    "                    obs_row.append('')\n",
    "                    r2_row.append('')\n",
    "            \n",
    "            table_data.append(obs_row)\n",
    "            table_data.append(r2_row)\n",
    "            \n",
    "            # Create table\n",
    "            table = ax.table(cellText=table_data, cellLoc='center', loc='center')\n",
    "            table.auto_set_font_size(False)\n",
    "            table.set_fontsize(8)\n",
    "            table.scale(1.2, 1.5)\n",
    "            \n",
    "            # Style the table\n",
    "            for i in range(len(headers)):\n",
    "                table[(0, i)].set_facecolor('#40466e')\n",
    "                table[(0, i)].set_text_props(weight='bold', color='white')\n",
    "            \n",
    "            plt.title(f'Regression Results: {file_name}', fontsize=14, fontweight='bold', pad=20)\n",
    "            pdf.savefig(fig, bbox_inches='tight')\n",
    "            plt.close()\n",
    "```\n",
    "\n",
    "Here is the Python error for this function:\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "ValueError                                Traceback (most recent call last)\n",
    "Cell In[9], line 328\n",
    "    325     print(f\"- Results saved in: {output_dir}/\")\n",
    "    327 if __name__ == \"__main__\":\n",
    "--> 328     main()\n",
    "\n",
    "Cell In[9], line 318, in main()\n",
    "    316 # Create PDF with results tables\n",
    "    317 pdf_output = os.path.join(output_dir, \"regression_results.pdf\")\n",
    "--> 318 create_results_table_pdf(all_results, pdf_output)\n",
    "    319 print(f\"PDF report saved to: {pdf_output}\")\n",
    "    321 # Print summary\n",
    "\n",
    "Cell In[9], line 240, in create_results_table_pdf(all_results, output_path)\n",
    "    237 table_data.append(r2_row)\n",
    "    239 # Create table\n",
    "--> 240 table = ax.table(cellText=table_data, cellLoc='center', loc='center')\n",
    "    241 table.auto_set_font_size(False)\n",
    "    242 table.set_fontsize(8)\n",
    "\n",
    "File ~\\Anaconda3\\lib\\site-packages\\matplotlib\\table.py:746, in table(ax, cellText, cellColours, cellLoc, colWidths, rowLabels, rowColours, rowLoc, colLabels, colColours, colLoc, loc, bbox, edges, **kwargs)\n",
    "    744 for row in cellText:\n",
    "    745     if len(row) != cols:\n",
    "--> 746         raise ValueError(\"Each row in 'cellText' must have {} columns\"\n",
    "    747                          .format(cols))\n",
    "    749 if cellColours is not None:\n",
    "    750     if len(cellColours) != rows:\n",
    "\n",
    "ValueError: Each row in 'cellText' must have 4 columns\n",
    "\n",
    "\n",
    "PLEASE FIX THIS ERROR\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def call_claude_api(prompt, api_key, model=\"claude-sonnet-4-20250514\"):\n",
    "    \"\"\"\n",
    "    Send a prompt to Claude API and return the response\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = anthropic.Anthropic(api_key=api_key)\n",
    "        \n",
    "        message = client.messages.create(\n",
    "            model=model,\n",
    "            max_tokens=8000,\n",
    "            temperature=0.50,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        return message.content[0].text\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error calling Claude API: {e}\")\n",
    "        return None\n",
    "\n",
    "def save_response(response, filename=\"fixed_function.txt\"):\n",
    "    \"\"\"\n",
    "    Save Claude's response to a file\n",
    "    \"\"\"\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(response)\n",
    "    print(f\"Fixed function saved to: {filename}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Check if API key is set\n",
    "    if API_KEY == \"your-api-key-here\":\n",
    "        print(\"Please replace 'your-api-key-here' with your actual API key\")\n",
    "        exit(1)\n",
    "    \n",
    "    print(\"Sending error fix request to Claude API...\")\n",
    "    response = call_claude_api(prompt, API_KEY)\n",
    "    \n",
    "    if response:\n",
    "        print(\"Response received!\")\n",
    "        print(\"-\" * 50)\n",
    "        print(response)\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Save the response\n",
    "        save_response(response, \"fixed_pdf_function.txt\")\n",
    "        \n",
    "        # Extract Python code if present\n",
    "        if \"```python\" in response:\n",
    "            code_start = response.find(\"```python\") + len(\"```python\")\n",
    "            code_end = response.find(\"```\", code_start)\n",
    "            if code_end != -1:\n",
    "                python_code = response[code_start:code_end].strip()\n",
    "                with open(\"fixed_create_results_table_pdf.py\", 'w', encoding='utf-8') as f:\n",
    "                    f.write(python_code)\n",
    "                print(\"Fixed function code saved to: fixed_create_results_table_pdf.py\")\n",
    "                print(\"\\nYou can now copy this function back into your main script.\")\n",
    "    else:\n",
    "        print(\"Failed to get response from Claude API\")\n",
    "        \n",
    "        \n",
    "# 4. Code below is from Claude (created above)\n",
    "#Copied and pasted in this box \n",
    "#This includes the copy and paste from Claude fixing the code for the create_results_table_pdf\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from linearmodels.panel import PanelOLS\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def generate_time_trend(df):\n",
    "    \"\"\"\n",
    "    Generate a time trend variable based on FYEAR\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    min_year = df['FYEAR'].min()\n",
    "    df['time_trend'] = df['FYEAR'] - min_year\n",
    "    return df\n",
    "\n",
    "def filter_data_around_regulation(df, window=2):\n",
    "    \"\"\"\n",
    "    Filter data to ±2 years around regulation year\n",
    "    Assumes regulation year is stored in 'Year' column\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # If 'Year' contains the regulation year for each observation\n",
    "    if 'Year' in df.columns:\n",
    "        df = df[(df['FYEAR'] >= df['Year'] - window) & \n",
    "                (df['FYEAR'] <= df['Year'] + window)]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def run_regression_specifications(df):\n",
    "    \"\"\"\n",
    "    Run three regression specifications with clustered standard errors\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # Ensure we have the required columns\n",
    "    required_cols = ['freqMF', 'treatment_effect', 'GVKEY', 'FYEAR']\n",
    "    control_vars = ['linstown', 'lsize', 'lbtm', 'lroa', 'lsaret12', \n",
    "                   'levol', 'lloss', 'lcalrisk', 'time_trend']\n",
    "    \n",
    "    # Check if all required columns exist\n",
    "    missing_cols = [col for col in required_cols + control_vars if col not in df.columns]\n",
    "    if missing_cols:\n",
    "        print(f\"Warning: Missing columns: {missing_cols}\")\n",
    "    \n",
    "    # Remove rows with missing values in key variables\n",
    "    key_vars = ['freqMF', 'treatment_effect', 'GVKEY', 'FYEAR']\n",
    "    df_clean = df.dropna(subset=key_vars)\n",
    "    \n",
    "    if len(df_clean) == 0:\n",
    "        print(\"No valid observations after cleaning\")\n",
    "        return results\n",
    "    \n",
    "    try:\n",
    "        # Specification 1: Baseline OLS (univariate)\n",
    "        formula1 = 'freqMF ~ treatment_effect'\n",
    "        model1 = ols(formula1, data=df_clean).fit(cov_type='cluster', \n",
    "                                                  cov_kwds={'groups': df_clean['GVKEY']})\n",
    "        \n",
    "        results['spec1_baseline'] = {\n",
    "            'formula': formula1,\n",
    "            'n_obs': int(model1.nobs),\n",
    "            'r_squared': float(model1.rsquared),\n",
    "            'coefficients': {},\n",
    "            't_stats': {},\n",
    "            'p_values': {},\n",
    "            'std_errors': {}\n",
    "        }\n",
    "        \n",
    "        for var in model1.params.index:\n",
    "            results['spec1_baseline']['coefficients'][var] = float(model1.params[var])\n",
    "            results['spec1_baseline']['t_stats'][var] = float(model1.tvalues[var])\n",
    "            results['spec1_baseline']['p_values'][var] = float(model1.pvalues[var])\n",
    "            results['spec1_baseline']['std_errors'][var] = float(model1.bse[var])\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in Specification 1: {e}\")\n",
    "        results['spec1_baseline'] = {'error': str(e)}\n",
    "    \n",
    "    try:\n",
    "        # Specification 2: OLS with control variables\n",
    "        available_controls = [var for var in control_vars if var in df_clean.columns]\n",
    "        control_formula = ' + '.join(available_controls)\n",
    "        formula2 = f'freqMF ~ treatment_effect + {control_formula}'\n",
    "        \n",
    "        # Remove rows with missing control variables\n",
    "        all_vars = ['freqMF', 'treatment_effect'] + available_controls\n",
    "        df_spec2 = df_clean.dropna(subset=all_vars)\n",
    "        \n",
    "        if len(df_spec2) > 0:\n",
    "            model2 = ols(formula2, data=df_spec2).fit(cov_type='cluster', \n",
    "                                                      cov_kwds={'groups': df_spec2['GVKEY']})\n",
    "            \n",
    "            results['spec2_controls'] = {\n",
    "                'formula': formula2,\n",
    "                'n_obs': int(model2.nobs),\n",
    "                'r_squared': float(model2.rsquared),\n",
    "                'coefficients': {},\n",
    "                't_stats': {},\n",
    "                'p_values': {},\n",
    "                'std_errors': {}\n",
    "            }\n",
    "            \n",
    "            for var in model2.params.index:\n",
    "                results['spec2_controls']['coefficients'][var] = float(model2.params[var])\n",
    "                results['spec2_controls']['t_stats'][var] = float(model2.tvalues[var])\n",
    "                results['spec2_controls']['p_values'][var] = float(model2.pvalues[var])\n",
    "                results['spec2_controls']['std_errors'][var] = float(model2.bse[var])\n",
    "        else:\n",
    "            results['spec2_controls'] = {'error': 'No observations after removing missing values'}\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in Specification 2: {e}\")\n",
    "        results['spec2_controls'] = {'error': str(e)}\n",
    "    \n",
    "    try:\n",
    "        # Specification 3: Panel regression with firm fixed effects\n",
    "        available_controls = [var for var in control_vars if var in df_clean.columns]\n",
    "        all_vars = ['freqMF', 'treatment_effect'] + available_controls + ['GVKEY', 'FYEAR']\n",
    "        df_spec3 = df_clean.dropna(subset=all_vars)\n",
    "        \n",
    "        if len(df_spec3) > 0:\n",
    "            # Set up panel data\n",
    "            df_spec3 = df_spec3.set_index(['GVKEY', 'FYEAR'])\n",
    "            \n",
    "            # Prepare variables for panel regression\n",
    "            y = df_spec3['freqMF']\n",
    "            X_vars = ['treatment_effect'] + available_controls\n",
    "            X = df_spec3[X_vars]\n",
    "            \n",
    "            # Run panel regression with entity fixed effects\n",
    "            model3 = PanelOLS(y, X, entity_effects=True).fit(cov_type='clustered', \n",
    "                                                              cluster_entity=True)\n",
    "            \n",
    "            results['spec3_fixed_effects'] = {\n",
    "                'n_obs': int(model3.nobs),\n",
    "                'r_squared': float(model3.rsquared),\n",
    "                'coefficients': {},\n",
    "                't_stats': {},\n",
    "                'p_values': {},\n",
    "                'std_errors': {}\n",
    "            }\n",
    "            \n",
    "            for var in model3.params.index:\n",
    "                results['spec3_fixed_effects']['coefficients'][var] = float(model3.params[var])\n",
    "                results['spec3_fixed_effects']['t_stats'][var] = float(model3.tstats[var])\n",
    "                results['spec3_fixed_effects']['p_values'][var] = float(model3.pvalues[var])\n",
    "                results['spec3_fixed_effects']['std_errors'][var] = float(model3.std_errors[var])\n",
    "        else:\n",
    "            results['spec3_fixed_effects'] = {'error': 'No observations after removing missing values'}\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in Specification 3: {e}\")\n",
    "        results['spec3_fixed_effects'] = {'error': str(e)}\n",
    "    \n",
    "    return results\n",
    "\n",
    "def create_results_table_pdf(all_results, output_path):\n",
    "    with PdfPages(output_path) as pdf:\n",
    "        for file_name, results in all_results.items():\n",
    "            fig, ax = plt.subplots(figsize=(12, 8))\n",
    "            ax.axis('tight')\n",
    "            ax.axis('off')\n",
    "            \n",
    "            # Create table data\n",
    "            table_data = []\n",
    "            headers = ['Variable', 'Spec 1: Baseline', 'Spec 2: Controls', 'Spec 3: Fixed Effects']\n",
    "            table_data.append(headers)\n",
    "            \n",
    "            # Get all variables across specifications\n",
    "            all_vars = set()\n",
    "            for spec_name in ['spec1_baseline', 'spec2_controls', 'spec3_fixed_effects']:\n",
    "                if spec_name in results and 'coefficients' in results[spec_name]:\n",
    "                    all_vars.update(results[spec_name]['coefficients'].keys())\n",
    "            \n",
    "            # Add coefficient and t-stat rows for each variable\n",
    "            for var in sorted(all_vars):\n",
    "                if var == 'Intercept':\n",
    "                    continue\n",
    "                    \n",
    "                coef_row = [var]\n",
    "                tstat_row = ['']\n",
    "                \n",
    "                for spec_name in ['spec1_baseline', 'spec2_controls', 'spec3_fixed_effects']:\n",
    "                    if (spec_name in results and \n",
    "                        'coefficients' in results[spec_name] and \n",
    "                        var in results[spec_name]['coefficients']):\n",
    "                        \n",
    "                        coef = results[spec_name]['coefficients'][var]\n",
    "                        tstat = results[spec_name]['t_stats'][var]\n",
    "                        pval = results[spec_name]['p_values'][var]\n",
    "                        \n",
    "                        # Add significance stars\n",
    "                        stars = ''\n",
    "                        if pval < 0.01:\n",
    "                            stars = '***'\n",
    "                        elif pval < 0.05:\n",
    "                            stars = '**'\n",
    "                        elif pval < 0.10:\n",
    "                            stars = '*'\n",
    "                        \n",
    "                        coef_row.append(f'{coef:.4f}{stars}')\n",
    "                        tstat_row.append(f'({tstat:.2f})')\n",
    "                    else:\n",
    "                        coef_row.append('')\n",
    "                        tstat_row.append('')\n",
    "                \n",
    "                table_data.append(coef_row)\n",
    "                table_data.append(tstat_row)\n",
    "            \n",
    "            # Add summary statistics with proper column count\n",
    "            # Add empty separator row with correct number of columns\n",
    "            table_data.append(['', '', '', ''])  # Fixed: now has 4 columns\n",
    "            \n",
    "            obs_row = ['Observations']\n",
    "            r2_row = ['R-squared']\n",
    "            \n",
    "            for spec_name in ['spec1_baseline', 'spec2_controls', 'spec3_fixed_effects']:\n",
    "                if spec_name in results and 'n_obs' in results[spec_name]:\n",
    "                    obs_row.append(str(results[spec_name]['n_obs']))\n",
    "                    r2_row.append(f\"{results[spec_name]['r_squared']:.4f}\")\n",
    "                else:\n",
    "                    obs_row.append('')\n",
    "                    r2_row.append('')\n",
    "            \n",
    "            table_data.append(obs_row)\n",
    "            table_data.append(r2_row)\n",
    "            \n",
    "            # Debug: Check all rows have same length\n",
    "            expected_cols = len(headers)\n",
    "            for i, row in enumerate(table_data):\n",
    "                if len(row) != expected_cols:\n",
    "                    print(f\"Row {i} has {len(row)} columns, expected {expected_cols}: {row}\")\n",
    "                    # Pad or trim row to correct length\n",
    "                    while len(row) < expected_cols:\n",
    "                        row.append('')\n",
    "                    if len(row) > expected_cols:\n",
    "                        row = row[:expected_cols]\n",
    "                        table_data[i] = row\n",
    "            \n",
    "            # Create table\n",
    "            table = ax.table(cellText=table_data, cellLoc='center', loc='center')\n",
    "            table.auto_set_font_size(False)\n",
    "            table.set_fontsize(8)\n",
    "            table.scale(1.2, 1.5)\n",
    "            \n",
    "            # Style the table\n",
    "            for i in range(len(headers)):\n",
    "                table[(0, i)].set_facecolor('#40466e')\n",
    "                table[(0, i)].set_text_props(weight='bold', color='white')\n",
    "            \n",
    "            plt.title(f'Regression Results: {file_name}', fontsize=14, fontweight='bold', pad=20)\n",
    "            pdf.savefig(fig, bbox_inches='tight')\n",
    "            plt.close()\n",
    "\n",
    "def main():\n",
    "    # Set directory path containing CSV files\n",
    "    data_directory = \"enter folder path here\"\n",
    "    if not data_directory:\n",
    "        data_directory = \".\"  # Current directory if no input\n",
    "    \n",
    "    # Output directory\n",
    "    output_dir = \"regression_results\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Check where files are saved\n",
    "    print(f\"Results will be saved to: {os.path.abspath(output_dir)}\")\n",
    "    \n",
    "    # Dictionary to store all results\n",
    "    all_results = {}\n",
    "    \n",
    "    # Process all CSV files in the directory\n",
    "    csv_files = list(Path(data_directory).glob(\"*.csv\"))\n",
    "    \n",
    "    if not csv_files:\n",
    "        print(f\"No CSV files found in {data_directory}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(csv_files)} CSV files to process\")\n",
    "    \n",
    "    for csv_file in csv_files:\n",
    "        print(f\"\\nProcessing: {csv_file.name}\")\n",
    "        \n",
    "        try:\n",
    "            # Read the data\n",
    "            df = pd.read_csv(csv_file)\n",
    "            print(f\"Loaded {len(df)} observations\")\n",
    "            \n",
    "            # Generate time trend variable\n",
    "            df = generate_time_trend(df)\n",
    "            \n",
    "            # Filter data to ±2 years around regulation year\n",
    "            df_filtered = filter_data_around_regulation(df, window=2)\n",
    "            print(f\"After filtering: {len(df_filtered)} observations\")\n",
    "            \n",
    "            if len(df_filtered) == 0:\n",
    "                print(\"No observations after filtering\")\n",
    "                continue\n",
    "            \n",
    "            # Run regression specifications\n",
    "            results = run_regression_specifications(df_filtered)\n",
    "            \n",
    "            # Store results\n",
    "            all_results[csv_file.stem] = results\n",
    "            \n",
    "            print(f\"Completed analysis for {csv_file.name}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {csv_file.name}: {e}\")\n",
    "            all_results[csv_file.stem] = {'error': str(e)}\n",
    "    \n",
    "    # Save results as JSON\n",
    "    json_output = os.path.join(output_dir, \"regression_results.json\")\n",
    "    with open(json_output, 'w') as f:\n",
    "        json.dump(all_results, f, indent=2)\n",
    "    print(f\"\\nResults saved to: {json_output}\")\n",
    "    \n",
    "    # Create PDF with results tables\n",
    "    pdf_output = os.path.join(output_dir, \"regression_results.pdf\")\n",
    "    create_results_table_pdf(all_results, pdf_output)\n",
    "    print(f\"PDF report saved to: {pdf_output}\")\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\nSummary:\")\n",
    "    print(f\"- Processed {len(csv_files)} files\")\n",
    "    print(f\"- Successful analyses: {len([r for r in all_results.values() if 'error' not in r])}\")\n",
    "    print(f\"- Results saved in: {output_dir}/\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
